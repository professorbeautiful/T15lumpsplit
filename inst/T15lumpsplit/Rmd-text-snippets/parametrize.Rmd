  <!-- https://engineering.purdue.edu/ECN/Support/KB/Docs/LaTeXChangingTheFont -->
  <!-- I suggest using \[   \] instead of $$    $$ and \(   \) for $   $. Also instead of using static \big( and \big), it is better to use dynamic \left( and \right) -->
  <!-- \raisebox{0.2ex} -->
  
**Setup**:  
The data from the table are the four numbers \[\mylarge{\bf{n}} = ({\mylarge{n}_{RD}},{\mylarge{n}_{RL}},{\mylarge{n}_{ND}},{\mylarge{n}_{NL}}).\]  

The outcome we call $Y$.  
The feature we call $X_{DL}$, or just $X$, 
with possible values $D$ or $L$. 
For example ${\mylarge{n}_{RD}}$  is shorthand for the number of patients  
for which the outcome $Y=R$ AND the feature $X=D$.

Parametrize the cell count probabilities as  
\[\mylarge{\bf{p}} = ({\mylarge{p}_{RD}},{\mylarge{p}_{RL}},{\mylarge{p}_{ND}},{\mylarge{p}_{NL}}).\]

For example ${\mylarge{p}_{RD}}$  is shorthand for the probability that  
the outcome is $Y=R$ and the feature is $X=D$.  
These four probabilities add to 1.


The likelihood function is  \[\mylarge{\ell} ({\bf{p}}) = (\mylarge{p}_{RD})^{{\mylarge{n}_{RD}}} ~~ (\mylarge{p}_{RL})^{{\mylarge{n}_{RL}}} ~~ (\mylarge{p}_{ND})^{{\mylarge{n}_{ND}}} ~~ (\mylarge{p}_{NL})^{{\mylarge{n}_{NL}}}\]  .

<!-- Using ~~ in place of \cdot -->

**Likelihood functions** are powerful tools in statistics,  
with many uses.
A likelihood function compares  
*different explanations*  
for the observed data.  
In this case, the "different explanations" are all the  
different possible values of the probability vector ${\bf{p}}$.

Different sampling plans have different distributions   
but do not affect the likelihood function.  
Multiplying a likelihood function with a number  
$$
K(\mylarge{\bf{n}})
$$  
that depends only on the observed data $\mylarge{\bf{n}}$  
and does not depend on the unknown "explanation"  
$$
\mylarge{\bf{p}}
$$  
does NOT change the likelihood function.   
In every use of the likelihood function,  that number $K$ washes out.


### Three sampling plans same likelihoods:  

####	If the study's **sample size is fixed** <br>at 100,  
then the model is *multinomial*,  
and the parametrization ${\bf{p}}$ given above is quite natural.
\[Pr(\mylarge{\bf{n}}~|~\mylarge{\bf{p}})~=~K(\mylarge{\bf{n}})~\mylarge{\ell} ({\bf{p}})\]
where $K~=~(100)!/({\mylarge{n}_{RD}}! ~{\mylarge{n}_{RL}}! ~{\mylarge{n}_{ND}}! ~{\mylarge{n}_{NL}}!)$.

####	If the **two bottom margins are fixed** <br>(6 and 94),  
the model is *a product of independent binomials*,  
and the natural parametrization is   
$({\mylarge{p}_{R~.~D}},{\mylarge{p}_{R~.~L}})$,  
where each ${\mylarge{p}_{R~.~X}}$ for $X \in  \{D,L\}$  
is the conditional probability  
  ${\mylarge{p}_{R~.~X}} = {\mylarge{p}_{RX}}/({\mylarge{p}_{RX}}+{\mylarge{p}_{NX}}))$.  
  Then $K$ is the product of the two binomial coefficients,  
  one for the $D$ margin and one for the $L$ margin:
  
  \[K~=~(\mylarge{n}_{RD}+ ~{\mylarge{n}_{ND}})!/({\mylarge{n}_{RD}}! ~{\mylarge{n}_{ND}}!) ~~~ (\mylarge{n}_{RL}+ ~{\mylarge{n}_{NL}})!/ ({\mylarge{n}_{RL}}! ~{\mylarge{n}_{NL}}!)\]
  
####	If **BOTH margin counts are fixed**  <br>(6 and 94, & 7 and 93), 
<img src='table fixed margins.png'>  

then the model is *hypergeometric*,  
and a natural parametrization is  
$({\mylarge{p}_D},{\mylarge{p}_R},~\mylarge{\phi} )$  
where $\phi$ is the odds ratio, and ${\mylarge{p}_D}$ and   ${\mylarge{p}_R}$  
are the
marginal probabilities.  (Details are omitted.)  
We pretend that it is the sampling model is impossible to implement  
when we use the Fisher "exact" test.  
Never is true (& never exact) in a clinical study. 

**SURPRISE!** 
All 3 sampling plans have the same **likelihood function**!  
The differences in sampling correspond to putting constraints on ${\bf{p}}$,  
and  different sample spaces for the data ${\bf{n}}$.

For the **"personalized medicine"** question at hand, 
the thing we care about is  
${\mylarge{p}_{R~|~D}}$,  
the probability of responding *R* given the patient is a *D* patient.
