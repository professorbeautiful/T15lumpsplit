
Dr. Who doesn't know *who* to believe.   
We stick with the idea that one and only one is correct.  
Maybe one’s correct ($\phi  = Split$ ),  
maybe the other one is ( $\phi  = Lump$). 

They each have a pretty strong opinion!  
Where might these guys' strong priors have come from?  
Search for the section "strong prior beliefs" below, then follow the link back here.
<!--
  `r go_to_section('Strong_prior_beliefs', 'Where do strong prior beliefs come from?') `.  
  (You can bounce back here after that.)  
  -->
  
  
But instead of making a choice, why not let the data guide  
a good ***compromise*** between the two viewpoints.  

The posterior distribution for Dr. Who,  
which averages ("marginalizes") over $\phi$,  
is a mixture. A "Bayesian" mixture.

We gaze at Dr. Who's "posterior"  
(surely there's an emoji for that):

```{r}
jumpList_DTC = c(jumpList_DTC, whoMixturePlot='Dr. Who\'s posterior: Bayes mixture')
source('analysisInitialSetup_DTC.R', local=TRUE); a(name=paste0('section-a_', analysisName) )

output$whoMixturePlot = 
  renderPlot(expr =  {
    analysisName = 'whoMixturePlot'
    source(analysisReactiveSetup_DTC, local=TRUE)
    pSeq = seq(0,1, length=100)
    par(mfrow=c(1,2))
    prior.s = dbeta(pSeq, 1, 1)
    prior.l = dbeta(pSeq, 2, 2)
    prior.w = rValues$WhoPriorProb * prior.s + (1-rValues$WhoPriorProb) * prior.l
    plot(pSeq, prior.s, col='blue', type='l',
         xlab='probability', ylab='density',
         ylim=c(0,15),
         main='Priors') 
    lines(pSeq, prior.l,  col='red')
    lines(pSeq, prior.w,  col='darkgreen', lwd=2)
    everyTenth = (1:length(pSeq)) %% 10 == 0
    points(pSeq[everyTenth], 
           prior.s[everyTenth], pch='S', col='blue')
    points(pSeq[everyTenth], 
           prior.l[everyTenth], pch='L', col='red')
    points(pSeq[everyTenth], 
           prior.w[everyTenth], pch='W', col='darkgreen')
    Sexpression = as.expression(
      bquote("S:  " * italic(
        p[R.D]) %~% italic(Be*ta)(1, 1) )  )
    text(0, 11, labels = Sexpression,
         col='blue', cex=1.5, pos=4
    )
    Lexpression = as.expression(
      bquote( "L:  " * italic(
        p[R.D]==p[R]) %~% Be*ta(2, 2) ) ) 
    text(0, 9, labels = Lexpression,
         col='red', cex=1.5, pos=4
    )
    Wexpression = as.expression(
      bquote( "W:  " * italic("Dr. Who mixture" ) ) )
    text(0, 7, labels = Wexpression,
         col='darkgreen', cex=1.5, pos=4
    )
#currentTableOfEstimates = tableOfEstimates()
    nRD=thisData['R','D']
    nND=thisData['N','D']
    posterior.s = dbeta(pSeq, 
                    1+nRD, 
                    1+nND)
    posterior.mean.s = (1+nRD)/(2+nRD+nND)
    nR=sum(thisData['R', ])
    nN=sum(thisData['N', ])
    posterior.mean.l = (2+nR)/(4+nN)
    posterior.l = dbeta(pSeq, 
                        2+nR, 2+nN)
    
    #cat('mSplit is ', mSplit(thisData), '\n')
    #cat('mLump is ', mLump(thisData), '\n')
    #cat('DrWhoBayesFactor is ', DrWhoBayesFactor(thisData), '\n')
    pProbSplit = posteriorProb(priorOdds = rValues$WhoPriorProb, theData=thisData)
    pProbLump = (1-pProbSplit)
    posterior.w = pProbSplit * posterior.s + pProbLump * posterior.l
    posterior.mean.w = 
      pProbSplit * posterior.mean.s +
      pProbLump * posterior.mean.l
    plot(pSeq, posterior.s, col='blue', type='l',
         xlab='probability', ylab='density',
         ylim=c(0,15),
         main='Posterior densities and means') 
    lines(pSeq, posterior.l,  col='red')
    lines(pSeq, posterior.w,  col='darkgreen', lwd=2)

    points(pSeq[everyTenth], posterior.s[everyTenth], 
           pch='S', col='blue')
    points(pSeq[everyTenth], posterior.l[everyTenth], 
           pch='L', col='red')
    points(pSeq[everyTenth], posterior.w[everyTenth], 
           pch='W', col='darkgreen')

    offset = 0.1
    Sexpression = as.expression(
      bquote("S:  " * italic(
        p[R.D]) %~% italic(Be*ta)(1+.(nRD), 1+.(nND))) ) 
    text(x = offset+0, 11, labels = Sexpression,
         col='blue', cex=1.5, pos=4, xpd=NA
    )
    Lexpression = as.expression(
      bquote( "L:  " * italic(
        p[R.D]==p[R]) %~% Be*ta(2+.(nR), 2+.(nN))) ) 
    text(offset+0, 9, labels = Lexpression,
         col='red', cex=1.5, pos=4, xpd=NA
    )
    Wexpression = as.expression(
      bquote( "W:  " * italic("Dr. Who mixture" ) ) )
    text(offset+0, 7, labels = Wexpression,
         col='darkgreen', cex=1.5, pos=4, xpd=NA
    )
    text(offset+0.2, 5, labels = 
           paste0(round(digits=2, pProbSplit)),
         col='darkgreen', cex=1.5, pos=4, xpd=NA
    )
    text(offset+0.35, 5, labels = "S",
         col='blue', cex=1.5, pos=4, xpd=NA)
    text(offset+0.45, 5, labels = "+",
         col='darkgreen', cex=1.5, pos=4, xpd=NA)
    text(offset+0.5, 5, labels = 
           paste0(round(digits=2, pProbLump)),
         col='darkgreen', cex=1.5, pos=4, xpd=NA
    )
    text(offset+0.65, 5, labels = "L",
         col='red', cex=1.5, pos=4)
    onTop = par('usr')[4]  ## ['y2']
    #cat('onTop: ', onTop, '\n')
    ######  Mark the positions of the means.
    text(0, onTop*1.05, col='black', xpd=NA, 
         labels=expression(Means %=>% phantom('.')), cex=1, pos = 2, font=4)
    text(posterior.mean.l, onTop*1.00, col='red', xpd=NA, labels="L", cex=1, pos = 3, font=4)
    text(posterior.mean.s, onTop*1.00, col='blue', xpd=NA, labels="S", cex=1, pos = 3, font=4)
    text(posterior.mean.w, onTop*1.00, col='darkgreen', xpd=NA, labels="W", cex=1, pos = 3, font=4)
  })
plotOutput('whoMixturePlot')
WhoPriorProbNumericInput()

dataTableComponent(showhide='hide', analysisName='whoMixturePlot')
TextQuestion("Experiment with changing #RL in the range 2 to 9. What happens?  And... why? ")
QandAha('QA-whoMixturePlot')
```

### The fundamental idea of Bayesian analysis, in 3 steps

```{r }

conditionalPanelWithCheckboxPDF(
  labelString="(A)  Define the problem", 
   filename='./Overview_of_Bayesian_calculation_A.pdf',
  cbStringId='bayes_decision_analysis_A')
```

What we care about is the probability of $R$ if the patient is a $D$.  
We also have a nuisance parameter all right: 
$\phi$:     whose prior opinion is right, is it $Split$ or $Lump$?
 
```{r}
conditionalPanelWithCheckboxPDF(
  labelString='(B)  Apply Bayes “theorem”:  Calculate the (posterior) distribution of the quantity of interest', 
   filename='./Overview_of_Bayesian_calculation_B.pdf',
  cbStringId='bayes_decision_analysis_B')
```

The details of the calculation in our case is here.


```{r}
conditionalPanelWithCheckboxPDF(
  labelString="(C)  Bayesian decision-making", 
   filename='./Overview_of_Bayesian_calculation_C.pdf',
  cbStringId='bayes_decision_analysis_C')
```


Great examples of Bayes decision-making are here:  
<a href="https://www.youtube.com/watch?v=c2IXn-rBl6k"  target='_blank'>  
"Episode 3: ***Dose Utility Explorer***, another "shiny" app. Expected Utility with Meihua Marie & Devlish Merry" </a>  

Yes, there's an <a href="https://trials.shinyapps.io/DUEshiny/" target='_blank'> app </a> for that. 


<!--
***Sidebar***:  
`r actionButton(class='sidebar', inputId='DrWho_prior_notation', 
label =  'DETAILS: Bayes calculation of Dr.Who\'s prior and posterior probability' )` 

```{r}
          
observe( {
  if(!is.null(input$DrWho_prior_notation) ) {
    if(input$DrWho_prior_notation > 0) {
        showModal(modalDialog(title="DETAILS: Bayes calculation of Dr. Who\'s prior and posterior probabilities", easyClose = T,
                               footer=modalButton('OK'),
                              inclRmd('DrWho_prior_notation.Rmd')))
    }
  }
}
)

```
 -->


