---
title: "Bias, variance, smoothing, and shrinking"
output: 
  html_document:
    css: lumpsplit.css
    number_sections: true
    toc: true
    toc_depth: 6
    toc_float: 
      collapsed: true
      smooth_scroll: false
runtime: shiny
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
options(knitr.duplicate.label = 'allow')
#options(error=browser)
require(T15lumpsplit)
require(shiny)
#source('rstudio.markdownToHTML.R', local=TRUE)
includeCSS('TOC.css')    ### includeCSS doesn't work here
includeCSS('lumpsplit.css')
```

```{r setup numbering, warning=FALSE}
try(rm(envNextNumber, pos=1), silent = TRUE)
try(rm(envNextNumberTOC, pos=1), silent = TRUE)
try(rm(envNextNumberQA, pos=1), silent = TRUE)
try(rm(envNextNumberTextQuestion, pos=1), silent = TRUE)
try(rm(envNextNumberDTC, pos=1), silent = TRUE)  ## data table
### Note that the .GlobalEnv seen here is different from your R session... and it persists across Rmd runs!

source('nextNumber.R', local=TRUE)
source('interactiveSection.R', local=TRUE)
source('QandAha.R', local=TRUE)
source('TextQuestion.R', local=TRUE)
```


```{r includeFunctions}
source('inclRmd.R', local=T)
source('linkout.R', local=T)
source('interactiveSection.R', local=T)
source('includeHTMLtrimmed.R', local=T)

```


```{r initial values, echo=FALSE}

logit = function(p) log(p/(1-p))
antilogit = function(x) 1 - 1/(1+exp(x))
DLdataOriginal = matrix(c(3,2,5,90),nrow=2)
dimnames(DLdataOriginal) = list( outcome=c("R","N"), feature=c("D","L"))
ColorForPrior="orange";     
ColorForPosterior="blue";     
ColorForLikelihood="black"
TOCnum =  0
```

```{r navTOCid.R}
#source('navTOCid.R', local=T)
```


```{r servercode}
source("Plight-Pdark-posterior-new.R", local=TRUE)
source("DrWhoBayesFactor.R")
rValues = reactiveValues(tau = 1,  phi = 0.001, mu=0.5,
                         title_1='title 1',
                         DLdata = DLdataOriginal,
                         DLdataMyChoice = DLdataOriginal,
                         isResetting = FALSE,
                         isLoopingSync = FALSE)
```

```{r plotPlightPdarkPosteriorReactive}
plotPlightPdarkPosteriorReactive = reactive( {
  cat("PLOTTING   ")
  tau <- input$tauInput
  phi <- input$phiInput
  mu0 <- input$mu0Input
  #cat("tau=", tau, " phi=", phi, " mu0=", mu0, "\n")
  rValues$bivariateNormResults <<-
    plotPlightPdarkPosterior(DLdata=rValues$DLdata,
                           tau=tau, phi=phi, mu0=logit(mu0), 
                           fudgeFactor = input$fudgeFactor,
                           showConfIntBinormal = TRUE
    )
  
  rValues$title_3 <<- paste0(
    "  tau=", input$tauInput,  
    ",  phi=", input$phiInput,  
    ",  mu0=", input$mu0Input 
  )
})
```


```{r lumpReact}
lumpReact = observe({
  if(length(input$lumpID) > 0) {
    cat("lumpID\n")
    rValues$tau <- 1; rValues$phi <- 0.001   
    ### Lump:  no individual variation:   D is same as L.
    rValues$title_1 <- "Dr. Lump"
    rValues$title_2 <- HTML("Prior belief: <br>Pr(R|D) = Pr(R|L)")
  }
})  
```


```{r splitReact}
splitReact = observe({
  if(length(input$splitID) > 0) {
    cat("splitID\n")
    rValues$tau <<- 0; rValues$phi <<- 1   
    ### Split:  D unconnected to L.
    rValues$title_1 <<- "Dr. Split"
    rValues$title_2 <<- HTML("Prior belief:<br> Pr(R|D) is unrelated to Pr(R|L).")
  }
}) 
```

```{r whoReact}
whoReact = observe({
  if(length(input$whoID) > 0) {
    cat("whoID\n")
    ### Who:  discrete mixture of Lump and Split.
    rValues$title_1 <<- "Dr. Who: \ndiscrete mixture of Lump and Split."
    rValues$title_2 <<- HTML("Prior belief: <BR> Pr(Lump)=Pr(Split)=1/2.")
  }
}) 
```

```{r mixedReact} 
mixedReact = observe({
  if(length(input$mixedID) > 0) {
    cat("mixedID\n")
    rValues$tau <<- 1/2; rValues$phi <<- 1/2 
    rValues$title_1 <<- HTML("Compromise: <br>lump some, split some")
    rValues$title_2 <<- HTML("Prior belief: <br> Pr(R|D) is somewhat related to Pr(R|L). ")
  }
})
```

```{r updateViews}
updateViews = observe({
  updateNumericInput(session=session, inputId="tauInput", 
                     value = rValues$tau)
  updateNumericInput(session=session, inputId="phiInput", 
                     value = rValues$phi)
})
```


```{r thePlot}
output$title_1_ID = renderUI({rValues$title_1})
output$title_2_ID = renderUI({rValues$title_2})
output$title_3_ID = renderUI({rValues$title_3})

output$thePlot = renderPlot(height=250,
                            {
                              par(mai=c(1,1,1,0.6))
                              par(mar=c(4,4,2,2) + 0.2)
                              #c(bottom, left, top, right)
                              par(pty='s')
                              plotPlightPdarkPosteriorReactive()
                            })
```

```{r makeDebuggingPanelOutput}
shinyDebuggingPanel::makeDebuggingPanelOutput(
  session, toolsInitialState = FALSE) 
```


```{r navTOCid.R.2}
#source('navTOCid.R', local=T)
```

```{r, results='asis'}
#cat("\U2B07")
# This shows you can get a fat arrow... but not in a plot.
```

```{r withDebuggingPanel}
##  <a name='debugging'>** **</a>
fluidRow(
  shinyDebuggingPanel::withDebuggingPanel() 
)
```

```{r conditionalPanelWithCheckbox}
conditionalPanelWithCheckbox = function(
  labelString, 
  filename,
  html='',
  initialValue=FALSE
) {
   labelStringNoSpaces = gsub("[ .'?!]", "_", labelString)
   labelStringId = paste0(labelStringNoSpaces, 'Id')
   cbStringId = paste0('cb', labelStringId)
  if(!missing(filename))
     html = c(tagList(inclRmd(filename)), html)
   output[[labelStringId]] <- renderUI({
     list(
       checkboxInput(cbStringId, 
                     strong(em(
                       paste0("show/hide the ", labelString))),
                     value=initialValue),
       conditionalPanel(condition = paste0('input.', cbStringId),
                        html )
     )
   })
   uiOutput(labelStringId)
}
```

```{r panelOfInputs}
panelOfInputs = 
  wellPanel(
    #checkboxInput(inputId= 'togglePanelOfInputs', label =
    HTML(
      'strong(em(
                    "Prior Distribution Inputs"))'), 
    #value = TRUE),
    #conditionalPanel(
    #  "input.togglePanelOfInputs",
    fluidRow(
      column(3, actionButton("lumpID", label = "Lump")),
      column(3, actionButton("splitID", label = "Split")),
      column(3, actionButton("mixedID", label = "Mixed")),
      column(3, numericInput(inputId = 'fudgeFactor', 
                   label = 'continuity fudge factor',
                   value=0.001))
    ),
    fluidRow(
      column(4,
             numericInput("phiInput", 
                          "prior variance | group (phi)", 
                          value=0, min = 0.00, step=0.1)),
      column(4,
             numericInput("tauInput", 
                          "shared additional variance (tau)", 
                          value=1, min = 0.00, step=0.1)
      ),
      column(4,
             numericInput("mu0Input", "shared prior mean (mu)", 
                          value=0.5, min = 0.001, step=0.1, max=0.999))
    )
  )
```


```{r show-hide-contours}
ContoursPanelLegend = list(
  div(style="color:orange", 
      checkboxInput("checkPrior", 
                    "Orange = prior distribution",
                    TRUE)),
  div(style="color:blue",
      checkboxInput("checkPosterior", 
                    "Blue = posterior distribution",
                    TRUE)),
  "Shaded: 50% highest posterior region",
#  "X:   observed data", br(),
  div(style='color:red',
      "L:  Dr.Lump's MP estimate", br(),
      "S:  Dr.Split's MP estimate", br(),
      "W:  Dr.Who's MP estimate"
  )
)
```

```{r responseRates}
output$responseRates = renderUI({
  splitLayout(HTML("Response <br>rates:"),
                HTML(paste(
                  input$mRD, '/', input$mRD+input$mND, 
                  "<br> = ",
                  signif(digits=3,
                        input$mRD/(input$mRD+input$mND)))),
                HTML(paste(
                  input$mRL, '/', input$mRL+input$mNL, 
                  "<br> = ", 
                  signif(digits=3,
                        input$mRL/(input$mRL+input$mNL))))
    )
  # paste(input$mRD, '/', input$mRD+input$mND, "for D, and ",
  #       input$mRL, '/', input$mRL+input$mNL, "for L.")
})
```

```{r data table}
source('dataTableComponent.R', local=TRUE)
```

```{r panelOfBifurcation}
output$fisherResult = renderUI({
    Pvalue = fisher.test(rValues$DLdata)$p.value
    div('Fisher exact test result:',
        br(),
        paste0('P = ', Pvalue, '\n')
    )
})
 
panelOfBifurcation = 
    conditionalPanelWithCheckbox(
      labelString = 'Classical bifurcated analysis',
      html = list(
  strong(em(span("P>0.05? then lump. P<0.05? then split"))),
  uiOutput('fisherResult')
#  checkboxInput('toggleShowFisher', 'Show/Hide the Fisher test', FALSE)
#)
      )
)
```



```{r UI_begins}
#### UI fluidPage####
require(shinyBS)
```
*Date: "`r date()`"     Author: "Roger Day, University of Pittsburgh"*

# OVERVIEW of this Module

```{r Overview}
conditionalPanelWithCheckbox(
  labelString = 'Overview', 
  filename = 'Overview.Rmd', html = '',
  initialValue = TRUE)
```
The general scope of the bias-variance axis in many settings is here:
```{r hide=TRUE}
interactiveSection(codeToRun="eval(parse(text=linkout('Reproducibility-lump-split-page-1.pdf')))", showResult = FALSE)
```

The list of topics developed or in development is here:
```{r topics}
conditionalPanelWithCheckbox(
  labelString = 'Topics', filename = 'topics.Rmd', initialValue=FALSE)
```

## The Lump versus Split Dilemma

```{r submoduleTitle}
##  <a name="LSnotebookBegin"> link The Lump versus Split Dilemma </a>
hr()
#h2(style="text-align: center;", ' h2 The Lump versus Split Dilemma')
hr()
```


```{r include notebook}
#div(
#  list(fluidRow(column(width = 8, 
         # wellPanel(id = "leftScrollPanel",
                   # style = "overflow-y:scroll; max-height: 600px"
         # ,
#         inclRmd('Submodule-LumpSplit.Rmd')
 #        ),
  # column(width = 4, 
  #       wellPanel(id = "leftScrollPanel",
  #                  style = "overflow-y:scroll; max-height: 600px"
  #        , 
         #panelOfData,
         #dataTableComponent(),
         #panelOfBifurcation,
         
#)
```

```{r listings}
source('initializations.R', local=TRUE)
# ls()
# cat('-=-=-=-=\n')
# ls(pos=1)
# cat('-=-=-=-=\n')
# so it has its own .GlobalEnv, and it's persistent across knits.
# wrapperToGetKeys  ### interesting! that's mine! from DebugTools
```



```{r hide=TRUE}
require('shiny')
```

### "Lumping" versus "splitting" in science. 

In science, advances often proceed by "splitting": things that seem initially the same are classified as different. The classification may be tentativedistinction, until it proves to be useful. 
Other advances proceed by "lumping":  identifying things that seem different but have a deep connection.

So, we split birds and bats, but we lump bats and whales because they are both mammals. At least in this case, for some purposes, lumping supercedes splitting.
(But if studying modes of  locomotion, the lumping will be different.)

In medicine both splitting and lumping are important.

Cancer was just "cancer" before it was learned through clinical trials that some medicines work well on cancer in one organ but not another--- and vice versa for another medicine.

In recent years, however, specific molecular defects in cancer cells have "lumped" together types of cancer that we would not have dreamed of connecting.
The drug gleevec is a miracle drug for patients with chronic myelogenous leukemia (CML). But not for other leukemias. Deep insight into molecular biology of cancer showed that a radically different kind, gastrointestinal stromal tumor (GIST). 
Better lumping together with better splitting can cure cancer patients.

We will explore a simple lumping and splitting conundrum as a jumping off point for introducing a collection of important statistical ideas that connect to each other.

```{r}
QandAha()
```

### Hypothetical medical study

The Problem:  A new treatment is given to 100 patients.  
Of them, only 8 respond.  But there is a subgroup of 5 in which 3 patients respond, yielding a response rate of 60%. for now we call them "D people", and the others "L people".

Goal: decide whether to treat the "D" patients (or at least, whether to put resources into studying it further for "D" patients).

If you *"lump"*, you will estimate that the response rate (`Pr(R|D)`) for D people is *8%*. 

If you *"split"*, you will estimate that the response rate (`Pr(R|D)`) for D people is *60%*. 

#### Plot of Lump and Split estimates

```{r plotLumpSplitPoints, fig.height=300}
output$plotLumpSplitPoints = renderPlot(
  height = 300, {
  plotPlightPdarkPosterior(DLdata=rValues$DLdata,
                           showPrior = FALSE, 
                           showPosterior=FALSE, showLikelihood=FALSE,
                           showS = TRUE,
                           showL = TRUE,
                           showW = FALSE)
  })
fluidRow(
  column(6, 
         # span(style='color:red; text-align:center', 
         # "L = Lump, S = Split"),
         plotOutput('plotLumpSplitPoints')),
  column(6,
         br(),br(),br(),
         dataTableComponent())
)
div(br(),br(),br())
```



Lumping gives an answer with low variance (N=100) but high bias-- because the answer reflects far more L  people than D people. The confidence interval follows the diagonal where $Pr(R|D)=Pr(R|L)$.

Splitting gives an answer with high variance (N=5) but low bias-- because it is including only people who ARE D:  it is directly asking our question. The very wide horizontal confidence interval reflects this high variance.


We will call the patient "feature" $X$. Its values is D or L.
The identity of $X$ will be explored later.

The outcome we call $Y$.  A responding patient has $Y=R$; non-reponding, $Y=N$.

#### Parametrizations of the probabilities

```{r child = 'Rmd-text-snippets/parametrize.Rmd'}
```

```{r}
#includeHTML('Rmd-text-snippets/parametrize.html')
#inclRmd('Rmd-text-snippets/parametrize.Rmd')
TextQuestion('Why focus on this parameter?')
```


```{r QA2}
QandAha()
```

#### Approaches

* [Classical test: is X independent of the outcome Y?](#Classical test)
* [Bayes mixture:  "Dr. Who"](#Bayes_mixture)
* [Bayes joint prior, logit scale](#Bayes_joint_prior).  
* Approaches used in the famous ECMO data set. (ToDo)

##### <a name='Classical test'> Classical estimation bifurcating on a hypothesis test</a>

A time-honored but fading technique is to use a classical hypothesis test, to guide which of two analyses to present.
Here the hypothesis is "X is independent of Y";  the response rate of D people does not differ from L people.  Then, depending on the hypothesis test result, Dr.Lump's answer or Dr. Split's answer is selected. 

One test frequently performed to test independence in a 2x2 table like this one is the *Fisher exact test*.

```{r fisher}
interactiveSection(
  codeToRun = "cat('P = ', fisher.test(DLdata)$p.value, '\n')",
  buttonLabel= "run fishertest")
```

If the P-value is "significant", the "null hypothesis" (that "Dr. Lump" is correct) is rejected. With the original data, the traditional consequence is that we use Dr. Split's estimate:  60%.
```{r}
QandAha()
```

##### <a name='Bayes_mixture'> Approach: Dr. Who's Bayes mixture of "Lump" and "Split"</a>

Dr. Who doesn't know *who* to believe, but is prepared to let the data make the right compromise.


```{r child = 'DrWho.Rmd'}
```



```{r QA3}
QandAha()
```


#####  Approach: Optimizing the mixture with cross-validation

Cross-validation is a technique in which the performance of a model can be checked as if on an independent dataset, without actually having a separate dataset. `K-fold cross-validation` divides the dataset into K disjoint subsets of observations, and loops over these sets. Each subset is, in turn, used as a `test set`. We remove it from the full dataset, re-build the model on the reduced dataset (the `training set`), and evaluate predictions of that model on the removed observations in the test set. Performance metrics are usually averaged across the K repetitions. When $K=N$, the size of the full dataset, the procedure is called `leave-one-out cross-validation`, since each test set is of size one.

For this example dataset, we perform leave-one-out cross-validation as follows:

```{r}
source('Lump-Split-crossvalidation.R', local=TRUE, echo = FALSE)
```
```{r}
fluidRow(
  column(6, 
         plotOutput('crossvalidationPlot')),
  column(6,
         br(),br(),br(),
         dataTableComponent())
)
```

##### Approach: Bayes joint prior on logits

##### <a name='Bayes_joint_prior'> Approach: Bayes joint prior, logit scale.</a>

Another Bayesian approach is to set a Bayesian prior on the joint distribution of the two conditional probabilities Pr(R|D) and Pr(R|L). This allows data on the two probabilities to be shared between them, smoothly instead of a crude mixture of the two extreme views of   "Dr. Lump" and "Dr. Split".
```{r}
QandAha()
```
Once we have this joint prior distribution, we compute the joint posterior.
```{r QA4}
QandAha()
```
To set the prior on the joint distribution of Pr(R|D) and Pr(R|L), we first convert them to logits ("logit" means "log(odds)"; details <a href='www/logit-info.htm').
Then we set a bivariate normal distribution on the logits.

We also convert the observed proportions to logits. We estimate the variances using the delta method applied to the Poisson distribution, whereby the variance of the logarithm of a count is roughly the reciprocal of the count.

(This doesn't work well if the count is near zero, and not at all at zero.
For this reason a "continuity fudge" is applied, if necessary.)

```{r}

output$postmean.p = renderText(
  paste0(
    signif(digits=2, rValues$bivariateNormResults$postmean.p[1]),
    ' (95% confidence interval: ', 
    signif(digits=2, rValues$bivariateNormResults$confints.p[1 , 1]),
    '-',
    signif(digits=2, rValues$bivariateNormResults$confints.p[2 , 1]),
    ')'
  )
)
```

Finally, Pr(R|D) marginalized over Pr(R|L) has posterior mean =  `r  (textOutput('postmean.p'))`  .

The link to bivariate normal details is here:

```{r linkoutbivariate}
  interactiveSection(codeToRun = 
linkout('./lump,split-bivariate-normal-derivation.pdf'))
```
```{r BayesLogitPlot}
#a(name='viewPlot')
div(
  fluidRow(
    column(6, 
           tagAppendAttributes(
             div(
               uiOutput(outputId="title_1_ID"),
               uiOutput(outputId="title_2_ID"),
               uiOutput(outputId="title_3_ID")
             ),
             style=
               'text-align:center; font-size:small;
                    font-weight:bold'),
           plotOutput(outputId = 'thePlot', height=260)
    ),
    column(6,
           br(),br(),br(),
           dataTableComponent()
    )
  ),
  fluidRow(
    column(4, 
           ContoursPanelLegend
    ),
    column(8,
           panelOfInputs
    )
  )
)
```


#### Summary of approaches 

Assembling the results of the approaches to estimating Pr(R|D):

```{r}
### ToDo

output$estimateTable = 
  renderTable(
    signif(digits=2, 
          data.frame(
            Lump=rValues$DLdata['R', ]/sum(rValues$DLdata[ , ]), 
            Split=rValues$DLdata['R','D']/sum(rValues$DLdata[ ,'D']), 
            Who=0.57, 
            CV=0.47, 
           BayesLogit=rValues$bivariateNormResults$postmean.p[1]
           )
    ))
### ToDo extract the point estimate from BayesLogit.
```

###  Save your Comments and Answers
```{r assembleComments}
assembleComments <<- function() {
  lastQANumber = nextNumber(sequenceType = "QA") - 1
  answers = sapply(1:lastQANumber, function(num) {
    outputIdThisQA = paste0('QA', num)
    textareaIdThisQA = paste0('id', outputIdThisQA)
    return(input[[textareaIdThisQA]])
  })
  unlist(answers[-which(sapply(answers, is.null))])
}
saveComments <<- function() {
  answers = assembleComments()
  writeLines(answers, file(paste0('answers.',
                                 Sys.info()["user"],
                                 '.txt'))
  )
}

interactiveSection(codeToRun = "saveComments()")
```

# Other topics to be developed:
##	The famous ECMO data set.
##	The role of prior information, explored by introducing different identities for "D" and "L".
###	2 alleles of a gene known to affect this drug's pharmacodynamics
###	2 alleles of one gene out of a hundred tested, chosen because they are known to affect this drug's pharmacodynamics
###	2 alleles of one gene out of a hundred thousand tested; nothing known
###	D = dark hair, L = light hair
###	D = dark hair, L = light hair; but hair color is strongly tied to ethnicityâ€¦ which is strongly tied to a key genetic variant
##	Curse of dimensionality,
##	Multiple testing and estimation with high-dimensional priors,


###### Other navigation links
## -> Top of the [Notebook](#notebookBegin) .
## -> [Debugging panel](#debugging) .
## -> [Code for the Plot](#plotCode).
## -> [viewPlot](#viewPlot).



### After the submodule

```{r}
#div(list(br(),br(),br(),br(),br(),br(),br(),br()))
```
```{r include navTOCid}
#source('navTOCid.R', local=T)
```
```{r}
#div(list(br(),br(),br(),br()))
```



